{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alexnet in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input image size: 227\\*227\\*3<br>\n",
    "- 第1层conv: <br>\n",
    "(3,96,kernel_size=(11,11), strid=4),outsize=(224-11 + 2\\*2)/4+1=55<br>\n",
    "参数数量为$3\\times 11 \\times 11 \\times 96 + 96 = 34944=3.5k$\n",
    "- 第2层maxpool:<br>\n",
    "(3,3,stride=2,pad=0),outsize=(55-3)/2+1=27\n",
    "- 第3层conv: <br>\n",
    "(96,256,kernel_size=(5,5), stride=1,pad=2),outsize=(27-5+2\\*2)/1+1=27<br>\n",
    "参数数量为$96\\times 5 \\times 5 \\times 256 + 256 = 614656=61.5k$\n",
    "- 第4层maxpool:<br>\n",
    "(3,3,stride=2),outsize=(27-3)/2+1=13\n",
    "- 第5层conv:<br>\n",
    "(256,384,kernel_size=(3,3), stride=1, pad=1),outsize=(13-3+2\\*1)/1+1=13<br>\n",
    "参数数量为$256\\times 3 \\times 3 \\times 384 + 384 = 885120=88.5k$\n",
    "- 第6层conv:<br>\n",
    "(384,256,kernel_size=(3,3), stride=1, pad=1),outsize=(13-3+2\\*1)/1+1=13<br>\n",
    "参数数量为$384\\times 3 \\times 3 \\times 256 + 256 = 884992=88.5k$\n",
    "- 第7层maxpool:<br>\n",
    "(3,3,stride=2),outsize=(13-3)/2+1=6\n",
    "reshape to vector,outsize=6\\*6\\*256=9216\n",
    "- 第8层fc:<br>\n",
    "(9216,4096),outsize=4096<br>\n",
    "参数数量为$9216\\times 4096 + 4096=37752832=37.7million$<br>\n",
    "- 第9层relu:<br>\n",
    "- 第10层fc:<br>\n",
    "(4096,4096),outsize=4096<br>\n",
    "参数数量为$4096\\times 4096 + 4096=16781312=16.7million$<br>\n",
    "- 第11层relu:<br>\n",
    "- 第12层fc:<br>\n",
    "(4096,1000),outsize=1000<br>\n",
    "参数数量为$4096\\times 1000 + 1000=4097000=4million$\n",
    "\n",
    "最后softmax\n",
    "\n",
    "总共参数数量为：60million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Alexnet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "        nn.Conv2d(3,96,11,stride=4,padding=0),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(3,stride=2),\n",
    "            \n",
    "        nn.Conv2d(96,256,5,stride=1,padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(3,stride=2),\n",
    "            \n",
    "        nn.Conv2d(256,384,3,stride=1,padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(384,256,3,stride=1,padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(3,stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(256*6*6, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(4096, 1000),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alexnet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = Alexnet()\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1145,  0.0334,  1.0321])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.randn(1,3,227,227)\n",
    "img[0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 6, 6])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = alexnet.features(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = alexnet(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alexnet in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "net = models.alexnet()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5358,  0.8940, -0.9849])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.randn(1,3,224,224)\n",
    "img[0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
